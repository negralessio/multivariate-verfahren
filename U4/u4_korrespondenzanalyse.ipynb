{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 2: Singulärwerte berechnen\n",
    "<img src=\"assets/Bildschirmfoto 2022-05-10 um 14.43.03.png\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Note:__\n",
    "Jede $(I \\times J)$ Matrix $A$ mit Rang $K$ kann gemäß der Singulärwertzerlegug wie folgt zerlegt werden: $$A = UDV' $$\n",
    "wobei\n",
    "- $D$ eine Diagonalmatrix ist mit Einträgen $\\alpha_1 ≥ \\alpha_2 ≥ ... ≥ \\alpha_K > 0$ ist\n",
    "- Die Matrizen $U$ und $V$ bestehen aus orthonormalen Vektoren $u_k$ und $v_k$ mit $k = 1, ..., K$. Ihre Spalten bilden jeweils eine (normierte) Basis eines $K$-dimensionalen Unterraums des $\\mathbb{R}^I$ bzw. $\\mathbb{R}^J$.\n",
    "- Es gilt $U'U = V'V = I_K$\n",
    "\n",
    "Definiert man $$F = UD \\text{ und } G = DV'$$ so erhält man die Koordinaten der Zeilen (bzw. Spalten) von $A$ bezüglich der Basisvektoren in $V$ (bzw. $U$). Der Ausdruck ganz oben, lässt sich auch schreiben als: $$A=\\sum_{k=1}^K \\alpha_k u_k v_k' $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonale matrix U = \n",
      "[[ 0.70710678  0.70710678]\n",
      " [ 0.70710678 -0.70710678]]\n",
      "Diagonalmatrix der Singularwerte D = \n",
      "[[3. 0.]\n",
      " [0. 1.]]\n",
      "Orthogonale Matrix V' = \n",
      "[[ 0.70710678  0.70710678]\n",
      " [-0.70710678  0.70710678]]\n",
      "Berechnung A = UDV\n",
      "[[1. 2.]\n",
      " [2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Gegebene Matrix:\n",
    "A = np.array([\n",
    "    [1, 2],\n",
    "    [2, 1]\n",
    "])\n",
    "\n",
    "# Compute Single Value Decomposition:\n",
    "## u = unitary/orthogonale matrix\n",
    "## s = Vector with the singular values\n",
    "## v = unitary/orthogonale matrix (already Transposed!)\n",
    "U, S, V = np.linalg.svd(a = A)\n",
    "# Invert sign (so its still correct)\n",
    "U = (-1) * U\n",
    "V = (-1) * V\n",
    "# Put s as diagonal matrix\n",
    "D = np.diag(S)\n",
    "print(f\"Orthogonale matrix U = \\n{U}\")\n",
    "print(f\"Diagonalmatrix der Singularwerte D = \\n{D}\")\n",
    "print(f\"Orthogonale Matrix V' = \\n{V}\")\n",
    "\n",
    "print(\"Berechnung A = UDV\")\n",
    "print(U @ D @ V)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "U und V sind orthogonale Matrizen bestehend aus orthonormalen Vektoren $u_k$ bzw. $v_k$ mit $k=1, ..., K$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA' =\n",
      " [[5 4]\n",
      " [4 5]]\n",
      "________________________________________________________________________________\n",
      "Eigenvalues and Eigenvectors of AA' = B:\n",
      "0th-Eigenvalue = 9.0\n",
      "0th-Eigenvectors = [0.70710678 0.70710678]\n",
      "1th-Eigenvalue = 1.0\n",
      "1th-Eigenvectors = [-0.70710678  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "# Eigenwerte und Eigenvektor von B = AA'\n",
    "B = A @ A.T\n",
    "print(f\"AA' =\\n {B}\")\n",
    "print(80 * \"_\")\n",
    "print(\"Eigenvalues and Eigenvectors of AA' = B:\")\n",
    "eigenvalue, eigenvector = np.linalg.eig(B)\n",
    "for i in range(2):\n",
    "    print(f\"{i}th-Eigenvalue = {eigenvalue[i]}\")\n",
    "    print(f\"{i}th-Eigenvectors = {eigenvector[:, i]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Approximiere A\n",
    "__Theorem 5.1.__ Wähle ein $K^* < K$. Dann minimiert die Matrix:\n",
    "$$ A_{[K^*]} := \\sum_{k=1}^{K^*} \\alpha_k u_k v_k' $$\n",
    "den Ausdruck\n",
    "$$ ||A - X||^2 = \\sum_i \\sum_j (a_{ij}-x_{ij})^2 $$\n",
    "unter allen $(I \\times J)$-Matrizen $X$ mit einem Rang von maximalen $K^*$.\n",
    "\n",
    "$A_{[K^*]}$ ist also die bestmöglichste Approximation von $A$ mit $Rang(K^*)$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2., -1.],\n       [ 1., -2.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wähle K* = 1\n",
    "K_STAR = 2\n",
    "A_K = 0\n",
    "\n",
    "for i in range(K_STAR):\n",
    "    A_K += S[i] * np.tensordot(a=U[:, i], b=V[:, i], axes=0)\n",
    "\n",
    "A_K"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (Singularvalue decomposition (SVD) example from Standford University, see [youtube](https://www.youtube.com/watch?v=P5mlg91as1c).)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "B = np.array([\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [3, 3, 3, 0, 0],\n",
    "    [4, 4, 4, 0, 0],\n",
    "    [5, 5, 5, 0, 0],\n",
    "    [0, 2, 0, 4, 4],\n",
    "    [0, 0, 0, 5, 5],\n",
    "    [0, 1, 0, 2, 2]\n",
    "])\n",
    "\n",
    "# Do SVD and round to 4 decimal places\n",
    "u, s, v = np.linalg.svd(B)\n",
    "u = np.around(u, 4)\n",
    "s = np.around(s, 4)\n",
    "v = np.around(v, 4)\n",
    "\n",
    "# B is User - Movie Rating Matrix. Row: User, Column: Movie, Entry: Rating\n",
    "# Each column in Matrix U represent a \"concept\". Every entry in column u how much a given user corresponds to a specific \"concept\". U is \"user-to-concept\" similarity matrix.\n",
    "# Singular values in s represent the \"strenghts\" of every \"concept\"\n",
    "# Matrix V is a \"movie-to-concept\" similarity matrix\n",
    "\n",
    "# SVD is used to learn \"concepts\" in our data. In the example from Stanford we identified the \"Sci-Fi Concepts\" and \"Romance Concept\", i.e. two movie categories. We can use that for recommendation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 2: Berechne die Totale Intertia einer gegebenen Häufigkeitstabelle\n",
    "<img height=\"100\" src=\"assets/Bildschirmfoto 2022-05-10 um 15.26.53.png\" width=\"300\"/>\n",
    "\n",
    "__Standardised Matrix Z:__\n",
    "$$ z_{ij} = \\frac{p_{ij}-\\hat{e}_{ij}}{\\sqrt{\\hat{e}_{ij}}} $$\n",
    "\n",
    "with $p_{ij} = \\frac{n_{ij}}{n}$ and $ \\hat{e}_{ij} = p_{i\\cdot} \\cdot p_{\\cdot j} $"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.21213203,  0.        ,  0.54935027],\n       [ 0.21213203,  0.        , -0.17928429]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given Data\n",
    "N = 20\n",
    "X = np.array([\n",
    "    [1, 4, 5],\n",
    "    [4, 4, 2]\n",
    "])\n",
    "\n",
    "# Transform X with absolut probability to relative probability, i.e. element wise division with N=20\n",
    "X = X / N\n",
    "\n",
    "# Compute relative feature occurence (relative Merkmalshäufigkeit)\n",
    "p_1x = np.sum(X[0, :])\n",
    "p_2x = np.sum(X[1, :])\n",
    "p_x1 = np.sum(X[:, 0])\n",
    "p_x2 = np.sum(X[:, 1])\n",
    "p_x3 = np.sum(X[:, 2])\n",
    "\n",
    "# Compute expected relative value matrix E\n",
    "E = np.array([\n",
    "    [p_1x * p_x1, p_1x * p_x2, p_x1 * p_x3],\n",
    "    [p_2x * p_x1, p_2x * p_x2, p_2x * p_x3]\n",
    "])\n",
    "\n",
    "# Standardize X\n",
    "Z = (X - E)/np.sqrt(E)\n",
    "\n",
    "# Preview\n",
    "Z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Total Inertia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Inertia T = 0.136949\n"
     ]
    }
   ],
   "source": [
    "# Compute Total Intertia T from standardised Matrix X, i.e. Z\n",
    "T = np.sum(Z) ** 2\n",
    "print(f\"Total Inertia T = {T:4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}